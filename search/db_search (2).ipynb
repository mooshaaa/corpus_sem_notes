{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1j6Ol17lbYTR"
      },
      "outputs": [],
      "source": [
        "# !pip install sqlite3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dlhTrTe7bYTS"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import sqlite3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X3ShVyGnbYTa"
      },
      "source": [
        "# И задаем запрос"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "db_file = 'sem_notes_corp.db'\n",
        "\n",
        "conn = sqlite3.connect(db_file)\n",
        "cursor = conn.cursor()\n",
        "\n",
        "# Запрос с несколькими JOIN\n",
        "cursor.execute(\"\"\"\n",
        "    SELECT DISTINCT doc_name\n",
        "    FROM DOCS\n",
        "\"\"\")\n",
        "\n",
        "# Получение результата\n",
        "res = cursor.fetchall()\n",
        "\n",
        "# Закрываем подключение\n",
        "conn.close()\n",
        "\n",
        "doc_names = [r[0] for r in res]\n",
        "doc_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "chaFNLccbAZp",
        "outputId": "e9449931-53e9-4076-d27e-88c02f3a8243"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['История семантики: основные этапы и имена.',\n",
              " 'Треугольник Фреге.',\n",
              " 'Теория референции.',\n",
              " 'Понятие интенсионала и экстенсионала.',\n",
              " 'Компонентный анализ.',\n",
              " 'Фон и фигура.',\n",
              " 'Траектор и ориентир.',\n",
              " 'Семантические роли.',\n",
              " 'Фреймовая семантика.',\n",
              " 'Синкретическое выражение семантических ролей.',\n",
              " 'Актанты и сирконстанты.',\n",
              " 'Семантические и синтаксические актанты.',\n",
              " 'Наследование актантов.',\n",
              " 'Компоненты значения.',\n",
              " 'Понятие сферы действия.',\n",
              " 'Фигура наблюдателя.',\n",
              " 'Понятие коннотации.',\n",
              " 'Отрицательная и положительная поляризация.',\n",
              " 'Полисемия.',\n",
              " 'Понятие семантического инварианта.',\n",
              " 'Основные типы семантических сдвигов.',\n",
              " 'Р.Якобсон о метафоре и метонимии.',\n",
              " 'А.Вежбицка о метафоре и сравнении.',\n",
              " 'Дж.Лакофф о концептуальной метафоре.',\n",
              " 'Концептуальный блендинг.',\n",
              " 'Е.В.Падучева о механизмах метафоры и метонимии.',\n",
              " 'Регулярная метонимия (типы с примерами).',\n",
              " 'Универсальная метафора.',\n",
              " 'Лексические функции.',\n",
              " 'Импликатура как механизм семантических сдвигов.',\n",
              " 'Грамматика конструкций.']"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "SoZy4EtkbYTa"
      },
      "outputs": [],
      "source": [
        "import sqlite3\n",
        "\n",
        "def get_sentences_with_lemma_only(db_file, lemma, doc_name=None, gender=None):\n",
        "    \"\"\"Выбирает предложения из таблицы SENT,\n",
        "    которые содержат слова с заданной леммой.\n",
        "    \"\"\"\n",
        "    conn = sqlite3.connect(db_file)\n",
        "    cursor = conn.cursor()\n",
        "    # Запрос с несколькими JOIN\n",
        "    if (doc_name != None) and (gender != None):\n",
        "        query = \"\"\"\n",
        "            SELECT DISTINCT WORD.sent_id, WORD.word_position, DOCS.doc_id\n",
        "            FROM WORD\n",
        "            JOIN SENT ON SENT.sent_id = WORD.sent_id\n",
        "            JOIN DOCS on DOCS.doc_id = SENT.doc\n",
        "            WHERE WORD.lemma = ? AND DOCS.gender = ? AND DOCS.doc_name IN ({seq})\n",
        "        \"\"\".format(seq=','.join(['?']*len(doc_name)))\n",
        "        cursor.execute(query, tuple([lemma] + [gender] + doc_name))\n",
        "    elif (doc_name == None) and (gender != None):\n",
        "        cursor.execute(\"\"\"\n",
        "            SELECT DISTINCT WORD.sent_id, WORD.word_position, DOCS.doc_id\n",
        "            FROM WORD\n",
        "            JOIN SENT ON SENT.sent_id = WORD.sent_id\n",
        "            JOIN DOCS on DOCS.doc_id = SENT.doc\n",
        "            WHERE WORD.lemma = ? AND DOCS.gender = ?\n",
        "        \"\"\", (lemma, gender))\n",
        "    elif (doc_name != None) and (gender == None):\n",
        "        query = \"\"\"\n",
        "            SELECT DISTINCT WORD.sent_id, WORD.word_position, DOCS.doc_id\n",
        "            FROM WORD\n",
        "            JOIN SENT ON SENT.sent_id = WORD.sent_id\n",
        "            JOIN DOCS on DOCS.doc_id = SENT.doc\n",
        "            WHERE WORD.lemma = ? AND DOCS.doc_name IN ({seq})\n",
        "        \"\"\".format(seq=','.join(['?']*len(doc_name)))\n",
        "        cursor.execute(query, tuple([lemma] + doc_name))\n",
        "    else:\n",
        "        cursor.execute(\"\"\"\n",
        "            SELECT DISTINCT WORD.sent_id, WORD.word_position, DOCS.doc_id\n",
        "            FROM WORD\n",
        "            JOIN SENT ON SENT.sent_id = WORD.sent_id\n",
        "            JOIN DOCS on DOCS.doc_id = SENT.doc\n",
        "            WHERE WORD.lemma = ?\n",
        "        \"\"\", (lemma,))\n",
        "\n",
        "    # Получение результата\n",
        "    result = cursor.fetchall()\n",
        "\n",
        "    # Закрываем подключение\n",
        "    conn.close()\n",
        "\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_sentences_with_wordform_only(db_file, wordform, doc_name=None, gender=None):\n",
        "    \"\"\"Выбирает предложения из таблицы SENT,\n",
        "    которые содержат слова с заданной словоформой.\n",
        "    \"\"\"\n",
        "\n",
        "    conn = sqlite3.connect(db_file)\n",
        "    cursor = conn.cursor()\n",
        "    # Запрос с несколькими JOIN\n",
        "    if (doc_name != None) and (gender != None):\n",
        "        query = \"\"\"\n",
        "            SELECT DISTINCT WORD.sent_id, WORD.word_position, DOCS.doc_id\n",
        "            FROM WORD\n",
        "            JOIN SENT ON SENT.sent_id = WORD.sent_id\n",
        "            JOIN DOCS on DOCS.doc_id = SENT.doc\n",
        "            WHERE WORD.word = ? AND DOCS.doc_name IN ({seq}) AND DOCS.gender = ?\n",
        "        \"\"\".format(seq=','.join(['?']*len(doc_name)))\n",
        "        cursor.execute(query, tuple([wordform] + doc_name + [gender]))\n",
        "    elif (doc_name == None) and (gender != None):\n",
        "        cursor.execute(\"\"\"\n",
        "            SELECT DISTINCT WORD.sent_id, WORD.word_position, DOCS.doc_id\n",
        "            FROM WORD\n",
        "            JOIN SENT ON SENT.sent_id = WORD.sent_id\n",
        "            JOIN DOCS on DOCS.doc_id = SENT.doc\n",
        "            WHERE WORD.word = ? AND DOCS.gender = ?\n",
        "        \"\"\", (wordform, gender))\n",
        "    elif (doc_name != None) and (gender == None):\n",
        "        query = \"\"\"\n",
        "            SELECT DISTINCT WORD.sent_id, WORD.word_position, DOCS.doc_id\n",
        "            FROM WORD\n",
        "            JOIN SENT ON SENT.sent_id = WORD.sent_id\n",
        "            JOIN DOCS on DOCS.doc_id = SENT.doc\n",
        "            WHERE WORD.word = ? AND DOCS.doc_name IN ({seq})\n",
        "        \"\"\".format(seq=','.join(['?']*len(doc_name)))\n",
        "        cursor.execute(query, tuple([wordform] + doc_name))\n",
        "    else:\n",
        "        cursor.execute(\"\"\"\n",
        "            SELECT DISTINCT WORD.sent_id, WORD.word_position, DOCS.doc_id\n",
        "            FROM WORD\n",
        "            JOIN SENT ON SENT.sent_id = WORD.sent_id\n",
        "            JOIN DOCS on DOCS.doc_id = SENT.doc\n",
        "            WHERE WORD.word = ?\n",
        "        \"\"\", (wordform,))\n",
        "\n",
        "\n",
        "    # Получение результата\n",
        "    result = cursor.fetchall()\n",
        "\n",
        "    # Закрываем подключение\n",
        "    conn.close()\n",
        "\n",
        "    return result"
      ],
      "metadata": {
        "id": "LusE1Jz6cpKI"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_sentences_with_lemma_tag(db_file, lemma, tag, doc_name=None, gender=None):\n",
        "    \"\"\"Выбирает предложения из таблицы SENT,\n",
        "    которые содержат слова с заданной леммой и тегом.\n",
        "    \"\"\"\n",
        "\n",
        "    conn = sqlite3.connect(db_file)\n",
        "    cursor = conn.cursor()\n",
        "\n",
        "    if (doc_name != None) and (gender != None):\n",
        "        query = \"\"\"\n",
        "            SELECT DISTINCT WORD.sent_id, WORD.word_position, DOCS.doc_id\n",
        "            FROM WORD\n",
        "            JOIN SENT ON SENT.sent_id = WORD.sent_id\n",
        "            JOIN DOCS on DOCS.doc_id = SENT.doc\n",
        "            WHERE WORD.lemma = ? and WORD.tag = ? AND DOCS.doc_name IN ({seq}) AND DOCS.gender = ?\n",
        "        \"\"\".format(seq=','.join(['?']*len(doc_name)))\n",
        "        cursor.exectue(query, tuple([lemma] + [tag] + doc_name + [gender]))\n",
        "    elif (doc_name == None) and (gender != None):\n",
        "        cursor.execute(\"\"\"\n",
        "            SELECT DISTINCT WORD.sent_id, WORD.word_position, DOCS.doc_id\n",
        "            FROM WORD\n",
        "            JOIN SENT ON SENT.sent_id = WORD.sent_id\n",
        "            JOIN DOCS on DOCS.doc_id = SENT.doc\n",
        "            WHERE WORD.lemma = ? and WORD.tag = ? AND DOCS.gender = ?\n",
        "        \"\"\", (lemma, tag, gender))\n",
        "    elif (doc_name != None) and (gender == None):\n",
        "        query = \"\"\"\n",
        "            SELECT DISTINCT WORD.sent_id, WORD.word_position, DOCS.doc_id\n",
        "            FROM WORD\n",
        "            JOIN SENT ON SENT.sent_id = WORD.sent_id\n",
        "            JOIN DOCS on DOCS.doc_id = SENT.doc\n",
        "            WHERE WORD.lemma = ? and WORD.tag = ? AND DOCS.doc_name IN ({seq})\n",
        "        \"\"\".format(seq=','.join(['?']*len(doc_name)))\n",
        "        cursor.execute(query, tuple([lemma] + [tag] + doc_name))\n",
        "    else:\n",
        "        cursor.execute(\"\"\"\n",
        "            SELECT DISTINCT WORD.sent_id, WORD.word_position, DOCS.doc_id\n",
        "            FROM WORD\n",
        "            JOIN SENT ON SENT.sent_id = WORD.sent_id\n",
        "            JOIN DOCS on DOCS.doc_id = SENT.doc\n",
        "            WHERE WORD.lemma = ? and WORD.tag = ?\n",
        "        \"\"\", (lemma, tag))\n",
        "\n",
        "    # Получение результата\n",
        "    result = cursor.fetchall()\n",
        "\n",
        "    # Закрываем подключение\n",
        "    conn.close()\n",
        "\n",
        "    return result"
      ],
      "metadata": {
        "id": "nYGrhHY-dAW4"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_sentences_with_wordform_tag(db_file, wordform, tag, doc_name=None, gender=None):\n",
        "    \"\"\"Выбирает предложения из таблицы SENT,\n",
        "    которые содержат слова с заданной словоформой и тегом.\n",
        "    \"\"\"\n",
        "    conn = sqlite3.connect(db_file)\n",
        "    cursor = conn.cursor()\n",
        "\n",
        "    if (doc_name != None) and (gender != None):\n",
        "        query = \"\"\"\n",
        "            SELECT DISTINCT WORD.sent_id, WORD.word_position, DOCS.doc_id\n",
        "            FROM WORD\n",
        "            JOIN SENT ON SENT.sent_id = WORD.sent_id\n",
        "            JOIN DOCS on DOCS.doc_id = SENT.doc\n",
        "            WHERE WORD.word = ? and WORD.tag = ? AND DOCS.doc_name IN ({seq}) AND DOCS.gender = ?\n",
        "        \"\"\".format(seq=','.join(['?']*len(doc_name)))\n",
        "        cursor.execute(query, tuple([wordform] + [tag] + doc_name + [gender]))\n",
        "    elif (doc_name == None) and (gender != None):\n",
        "        cursor.execute(\"\"\"\n",
        "            SELECT DISTINCT WORD.sent_id, WORD.word_position, DOCS.doc_id\n",
        "            FROM WORD\n",
        "            JOIN SENT ON SENT.sent_id = WORD.sent_id\n",
        "            JOIN DOCS on DOCS.doc_id = SENT.doc\n",
        "            WHERE WORD.word = ? and WORD.tag = ? AND DOCS.gender = ?\n",
        "        \"\"\", (wordform, tag, gender))\n",
        "    elif (doc_name != None) and (gender == None):\n",
        "        query = \"\"\"\n",
        "            SELECT DISTINCT WORD.sent_id, WORD.word_position, DOCS.doc_id\n",
        "            FROM WORD\n",
        "            JOIN SENT ON SENT.sent_id = WORD.sent_id\n",
        "            JOIN DOCS on DOCS.doc_id = SENT.doc\n",
        "            WHERE WORD.word = ? and WORD.tag = ? AND DOCS.doc_name IN ({seq})\n",
        "        \"\"\".format(seq=','.join(['?']*len(doc_name)))\n",
        "        cursor.execute(query, tuple([wordform] + [tag] + doc_name))\n",
        "    else:\n",
        "        cursor.execute(\"\"\"\n",
        "            SELECT DISTINCT WORD.sent_id, WORD.word_position, DOCS.doc_id\n",
        "            FROM WORD\n",
        "            JOIN SENT ON SENT.sent_id = WORD.sent_id\n",
        "            JOIN DOCS on DOCS.doc_id = SENT.doc\n",
        "            WHERE WORD.word = ? and WORD.tag = ?\n",
        "        \"\"\", (wordform, tag))\n",
        "\n",
        "    # Получение результата\n",
        "    result = cursor.fetchall()\n",
        "\n",
        "    # Закрываем подключение\n",
        "    conn.close()\n",
        "\n",
        "    return result"
      ],
      "metadata": {
        "id": "kw66J_RQdXKd"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_sentences_with_tag(db_file, tag, doc_name=None, gender=None):\n",
        "    \"\"\"Выбирает предложения из таблицы SENT,\n",
        "    которые содержат слова с заданным тегом.\n",
        "    \"\"\"\n",
        "    conn = sqlite3.connect(db_file)\n",
        "    cursor = conn.cursor()\n",
        "\n",
        "    if (doc_name != None) and (gender != None):\n",
        "        query = \"\"\"\n",
        "            SELECT DISTINCT WORD.sent_id, WORD.word_position, DOCS.doc_id\n",
        "            FROM WORD\n",
        "            JOIN SENT ON SENT.sent_id = WORD.sent_id\n",
        "            JOIN DOCS on DOCS.doc_id = SENT.doc\n",
        "            WHERE WORD.tag = ? AND DOCS.doc_name IN ({seq}) AND DOCS.gender = ?\n",
        "        \"\"\".format(seq=','.join(['?']*len(doc_name)))\n",
        "        cursor.execute(query, tuple([tag] + doc_name + [gender]))\n",
        "    elif (doc_name == None) and (gender != None):\n",
        "        cursor.execute(\"\"\"\n",
        "            SELECT DISTINCT WORD.sent_id, WORD.word_position, DOCS.doc_id\n",
        "            FROM WORD\n",
        "            JOIN SENT ON SENT.sent_id = WORD.sent_id\n",
        "            JOIN DOCS on DOCS.doc_id = SENT.doc\n",
        "            WHERE WORD.tag = ? AND DOCS.gender = ?\n",
        "        \"\"\", (tag, gender))\n",
        "    elif (doc_name != None) and (gender == None):\n",
        "        query = \"\"\"\n",
        "            SELECT DISTINCT WORD.sent_id, WORD.word_position, DOCS.doc_id\n",
        "            FROM WORD\n",
        "            JOIN SENT ON SENT.sent_id = WORD.sent_id\n",
        "            JOIN DOCS on DOCS.doc_id = SENT.doc\n",
        "            WHERE WORD.tag = ? AND DOCS.doc_name IN ({seq})\n",
        "        \"\"\".format(seq=','.join(['?']*len(doc_name)))\n",
        "        cursor.execute(query, tuple([tag] + doc_name))\n",
        "    else:\n",
        "        cursor.execute(\"\"\"\n",
        "            SELECT DISTINCT WORD.sent_id, WORD.word_position, DOCS.doc_id\n",
        "            FROM WORD\n",
        "            JOIN SENT ON SENT.sent_id = WORD.sent_id\n",
        "            JOIN DOCS on DOCS.doc_id = SENT.doc\n",
        "            WHERE WORD.tag = ?\n",
        "        \"\"\", (tag, ))\n",
        "\n",
        "\n",
        "    # Получение результата\n",
        "    result = cursor.fetchall()\n",
        "\n",
        "    # Закрываем подключение\n",
        "    conn.close()\n",
        "\n",
        "    return result"
      ],
      "metadata": {
        "collapsed": true,
        "id": "NmzS9QasDqxJ"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pymorphy2"
      ],
      "metadata": {
        "id": "pueLHOuNg1ZI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "052aef5a-f7f7-4f1e-e12f-46a0ca06b5b4"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pymorphy2\n",
            "  Downloading pymorphy2-0.9.1-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting dawg-python>=0.7.1 (from pymorphy2)\n",
            "  Downloading DAWG_Python-0.7.2-py2.py3-none-any.whl.metadata (7.0 kB)\n",
            "Collecting pymorphy2-dicts-ru<3.0,>=2.4 (from pymorphy2)\n",
            "  Downloading pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting docopt>=0.6 (from pymorphy2)\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Downloading pymorphy2-0.9.1-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.5/55.5 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading DAWG_Python-0.7.2-py2.py3-none-any.whl (11 kB)\n",
            "Downloading pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl (8.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.2/8.2 MB\u001b[0m \u001b[31m56.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: docopt\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=644887a09b669d85f19219d367019848e6a8a52ad5b475fb49dbbcea70380179\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n",
            "Successfully built docopt\n",
            "Installing collected packages: pymorphy2-dicts-ru, docopt, dawg-python, pymorphy2\n",
            "Successfully installed dawg-python-0.7.2 docopt-0.6.2 pymorphy2-0.9.1 pymorphy2-dicts-ru-2.4.417127.4579844\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pymorphy2\n",
        "\n",
        "morph = pymorphy2.MorphAnalyzer()"
      ],
      "metadata": {
        "id": "rcSjszAegqhB"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_tags = ['A', 'ADV', 'ADVPRO', 'ANUM', 'APRO',\n",
        "            'COM', 'CONJ', 'INTJ', 'NUM', 'PART',\n",
        "            'PR', 'S', 'SPRO', 'V']"
      ],
      "metadata": {
        "id": "pW2cP0hMVtI8"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def search(query, db_file, doc_name=None, gender=None):\n",
        "    \"\"\"Выбирает предложения из таблицы SENT,\n",
        "    которые содержат поисковый запрос.\n",
        "    \"\"\"\n",
        "\n",
        "    # делим запрос на части\n",
        "    query_parts = query.split()\n",
        "    # счетчик по предложениям\n",
        "    wp = None\n",
        "    # для каждой части запроса\n",
        "    for query_part in query_parts:\n",
        "        # делим запрос по знаку + (если вдруг есть тег)\n",
        "        part = query_part.split('+')\n",
        "        # если есть тег\n",
        "        if len(part) == 2:\n",
        "            # отдельно записываем слово и тег\n",
        "            word, tag = part[0], part[1]\n",
        "            # если мы ищем словоформу\n",
        "            if word[0] and word[-1] == '\"':\n",
        "                # находим все предложения со словоформой\n",
        "                # (предложение, номер в предложении)\n",
        "                sentences = get_sentences_with_wordform_tag(db_file, word, tag, doc_name, gender)\n",
        "                # если счетчик не задан (первый элемент запроса)\n",
        "                if wp == None:\n",
        "                    # делаем словарь\n",
        "                    # предложение: номер в предложении\n",
        "                    wp = {s[0]: [s[1]] for s in sentences}\n",
        "                # если уже задан (то есть не первый элемент)\n",
        "                else:\n",
        "                    for s in sentences:\n",
        "                        if s[0] in wp:\n",
        "                            if wp[s[0]][-1] == s[1] - 1:\n",
        "                                wp[s[0]].append(s[1])\n",
        "                            else:\n",
        "                                del wp[s[0]]\n",
        "            # если ищем лемму\n",
        "            else:\n",
        "                # собственно лемма\n",
        "                word = morph.parse(word)[0].normal_form\n",
        "                # дальше то же самое\n",
        "                sentences = get_sentences_with_lemma_tag(db_file, word, tag, doc_name, gender)\n",
        "                if wp == None:\n",
        "                    wp = {s[0]: [s[1]] for s in sentences}\n",
        "                    # sents.append(sentences)\n",
        "                else:\n",
        "                    for s in sentences:\n",
        "                        if s[0] in wp:\n",
        "                            if wp[s[0]][-1] == s[1] - 1:\n",
        "                                wp[s[0]].append(s[1])\n",
        "                            else:\n",
        "                                del wp[s[0]]\n",
        "        # если тега нет\n",
        "        else:\n",
        "            # то же самое, что раньше\n",
        "            word = part[0]\n",
        "            if word[0] and word[-1] == '\"':\n",
        "                sentences = get_sentences_with_wordform_only(db_file, word, doc_name, gender)\n",
        "                if wp == None:\n",
        "                    wp = {s[0]: [s[1]] for s in sentences}\n",
        "                    # sents.append(sentences)\n",
        "                else:\n",
        "                    for s in sentences:\n",
        "                        if s[0] in wp:\n",
        "                            if wp[s[0]][-1] == s[1] - 1:\n",
        "                                wp[s[0]].append(s[1])\n",
        "                            else:\n",
        "                                del wp[s[0]]\n",
        "            else:\n",
        "                if word not in all_tags:\n",
        "                    word = morph.parse(word)[0].normal_form\n",
        "                    sentences = get_sentences_with_lemma_only(db_file, word, doc_name, gender)\n",
        "                else:\n",
        "                    sentences = get_sentences_with_tag(db_file, word, doc_name, gender)\n",
        "                if wp == None:\n",
        "                    wp = {s[0]: [s[1]] for s in sentences}\n",
        "                    # sents.append(sentences)\n",
        "                else:\n",
        "                    for s in sentences:\n",
        "                        if s[0] in wp:\n",
        "                            if wp[s[0]][-1] == s[1] - 1:\n",
        "                                wp[s[0]].append(s[1])\n",
        "                            else:\n",
        "                                del wp[s[0]]\n",
        "    sents = [elem for elem in wp if len(wp[elem]) == len(query_parts)]\n",
        "    # sents = list(wp.keys())\n",
        "    conn = sqlite3.connect(db_file)\n",
        "    cursor = conn.cursor()\n",
        "    # Запрос с несколькими JOIN\n",
        "    cursor.execute(\"\"\"\n",
        "        SELECT DISTINCT DOCS.gender, DOCS.doc_name, SENT.sentence_text\n",
        "        FROM SENT\n",
        "        JOIN DOCS on DOCS.doc_id = SENT.doc\n",
        "        WHERE SENT.sent_id IN ({seq})\"\"\".format(\n",
        "    seq=','.join(['?']*len(sents))), sents)\n",
        "\n",
        "    # Получение результата\n",
        "    result = cursor.fetchall()\n",
        "\n",
        "    # Закрываем подключение\n",
        "    conn.close()\n",
        "\n",
        "    output = {}\n",
        "\n",
        "    for r in result:\n",
        "        if r[2] not in output:\n",
        "            output[r[2]] = {'Название конспекта': r[1],\n",
        "                            'Пол автора': r[0],\n",
        "                            'Год': 2023}\n",
        "    return output"
      ],
      "metadata": {
        "id": "xOewjIKzdlB2"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%time\n",
        "search('A рамка', 'sem_notes_corp.db', doc_name=['Компоненты значения.', 'Отрицательная и положительная поляризация.'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JnOiGOsOf-8J",
        "outputId": "40d23311-8035-48da-b4e2-e80b25b7bfd0"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 4 µs, sys: 0 ns, total: 4 µs\n",
            "Wall time: 8.34 µs\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Модальная рамка.': {'Название конспекта': 'Компоненты значения.',\n",
              "  'Пол автора': 'f',\n",
              "  'Год': 2023},\n",
              " 'Это не пресуппозиция и не ассерция: сочетание отрицания с, например, словами, обеспечивающими модальную рамку, в принципе аномально (см.': {'Название конспекта': 'Компоненты значения.',\n",
              "  'Пол автора': 'f',\n",
              "  'Год': 2023},\n",
              " 'Заметим, что *Он выпил не всего два бокала вина нельзя, слова с модальной рамкой с отрицанием не сочетаются.': {'Название конспекта': 'Компоненты значения.',\n",
              "  'Пол автора': 'f',\n",
              "  'Год': 2023},\n",
              " 'PPI не сочетаются с отрицанием, потому что многие PPI – слова, состоящие из одной модальной рамки.': {'Название конспекта': 'Отрицательная и положительная поляризация.',\n",
              "  'Пол автора': 'f',\n",
              "  'Год': 2023}}"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}